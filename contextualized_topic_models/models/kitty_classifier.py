from contextualized_topic_models.models.ctm import ZeroShotTM
from contextualized_topic_models.utils.preprocessing import WhiteSpacePreprocessing
from contextualized_topic_models.utils.data_preparation import TopicModelDataPreparation
import numpy as np


class Kitty:
    """
    Kitty is a utility to generate a simple classifiers from a topic model. It first run
    a CTM instance on the data for you and you can then select a set of topics of interest. Once
    this is done, you can apply this selection to a wider range of documents.
    """
    def __init__(self):

        self._assigned_classes = {}
        self.ctm = None
        self.qt = None
        self.topics_num = 0

    def train(self, documents,
              topics=10,
              embedding_model="paraphrase-distilroberta-base-v2",
              epochs=10,
              contextual_size=768,
              n_words=2000,
              language="english"):
        """
        :param documents: list of documents to train the topic model
        :param topics: number of topics to use to fit the topic model
        :param embedding_model: the embedding model used to create the embeddings
        :param epochs: number of epochs used to train the model
        :param contextual_size: size of the embeddings generated by the embedding model
        :param n_words: maximum number of words to take into consideration
        :param language: language for stopwords removal
        """
        self.topics_num = topics
        self._assigned_classes = {k: "other" for k in range(0, self.topics_num)}

        sp = WhiteSpacePreprocessing(documents, language, n_words)
        preprocessed_documents, unpreprocessed_documents, vocab = sp.preprocess()

        self.qt = TopicModelDataPreparation(embedding_model, show_warning=False)
        training_dataset = self.qt.fit(text_for_contextual=unpreprocessed_documents,
                                       text_for_bow=preprocessed_documents)

        self.ctm = ZeroShotTM(bow_size=len(vocab),
                              contextual_size=contextual_size,
                              n_components=topics,
                              num_epochs=epochs)

        self.ctm.fit(training_dataset)  # run the model

    def get_word_classes(self) -> list:
        return self.ctm.get_topic_lists(5)

    def pretty_print_word_classes(self):
        return "\n".join(str(a) + "\t" + ", ".join(b) for a, b in enumerate(self.get_word_classes()))

    @property
    def assigned_classes(self):
        return self._assigned_classes

    @assigned_classes.setter
    def assigned_classes(self, classes):
        """
        :param classes: a dictionary with the manually mapped topics to the classes e.g., {0 : "nature", 1 : "news"}
        """
        self._assigned_classes = {k: "other" for k in range(0, self.topics_num)}
        self._assigned_classes.update(classes)

    def predict(self, texts):
        """
        :param texts: a list of texts to be classified
        """

        if set(self._assigned_classes.values()) == set("other"):
            raise Exception("Only ``other'' classes are present, did you assign the topics to the assigned_class "
                            "property?")

        data = self.qt.transform(texts)
        topic_ids = np.argmax(self.ctm.get_doc_topic_distribution(data), axis=1)

        return [self._assigned_classes[k] for k in topic_ids]








